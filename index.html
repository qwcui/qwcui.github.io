<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qiwen Cui</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="cv.pdf">CV</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qiwen Cui</h1>
</div>
<table class="imgtable"><tr><td>
<img src="profile1.jpeg" alt="alt text" width="150px" height="200px" />&nbsp;</td>
<td align="left"><p>Qiwen Cui<br />
Ph.D. student<br />
<a href="https://www.cs.washington.edu">Paul G. Allen School of Computer Science &amp; Engineering</a><br /> 
<a href="https://www.washington.edu">University of Washington</a><br /> 
Email: qwcui <a href="at">at</a> cs (dot) washington (dot) edu<br />
<a href="https://scholar.google.com/citations?user=AnSVkUYAAAAJ&amp;hl=en">Google Scholar</a> </p>
</td></tr></table>
<h2>About me</h2>
<p>I am a final year Ph.D. student in the Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington. I am very fortunate to be advised by Professor <a href="https://simonshaoleidu.com">Simon Shaolei Du</a>. Prior to starting my Ph.D. study, I did my undergrad in the <a href="https://www.math.pku.edu.cn/en/">School of Mathematical Sciences</a> at <a href="https://english.pku.edu.cn">Peking University</a> advised by Professor
<a href="https://bicmr.pku.edu.cn/~wenzw/">Zaiwen Wen</a>. I had a great summer working with Professor <a href="http://drlinyang.net">Lin F. Yang</a> in 2020, who led me into the world of reinforcement learning theory.</p>
<p>My research interests are in reinforcement learning. I have been working on designing provably efficient multi-agent reinforcement learning algorithms for the offline case (exploiting the dataset) and the online case (exploring the structured environment). I have also done research in optimization and game theory. I am also interested in the role of RL(HF) in the performance of LLMs. </p>
<h2>Selected Publications </h2>
<h3>Offline Multi-agent Reinforcement Learning </h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2409.00717">Multi-Agent Reinforcement Learning from Human Feedback: Data Coverage and Algorithmic Techniques</a><br />
Natalia Zhang*, Xinqi Wang*, <b>Qiwen Cui</b>*, Runlong Zhou, Sham M Kakade, Simon S Du<br />
ArXiv: 2409.00717</p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.00159">Provably Efficient Offline Multi-agent Reinforcement Learning via Strategy-wise Bonus</a><br /> 
<b>Qiwen Cui</b>, Simon S. Du<br />
Conference on Neural Information Processing Systems (NeurIPS) 2022<br /> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2201.03522">When is Offline Two-Player Zero-Sum Markov Game Solvable?</a><br /> 
<b>Qiwen Cui</b>, Simon S. Du<br />
Conference on Neural Information Processing Systems (NeurIPS) 2022<br /> </p>
</li>
</ul>
<h3>Online Multi-agent Reinforcement Learning</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.07082">Refined Sample Complexity for Markov Games with Independent Linear Function Approximation</a><br />
Yan Dai, <b>Qiwen Cui</b>, Simon S. Du<br />
The 37th Annual Conference on Learning Theory (COLT) 2024<br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2306.07465">A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning</a><br />
Haozhe Jiang, <b>Qiwen Cui</b>, Zhihan Xiong, Maryam Fazel, Simon S. Du<br />
International Conference on Learning Representations (ICLR) 2024<br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2302.03673">Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation</a><br />
<b>Qiwen Cui</b>, Kaiqing Zhang, Simon S. Du<br />
The 36th Annual Conference on Learning Theory (COLT) 2023<br /></p>
</li>
</ul>
<h3>Learning in Congestion Games</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.07437">Learning Optimal Tax Design in Nonatomic Congestion Games</a><br />
<b>Qiwen Cui</b>, Maryam Fazel, Simon S. Du<br />
Conference on Neural Information Processing Systems (NeurIPS) 2024<br /> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2210.13396">Offline Congestion Games: How Feedback Type Affects Data Coverage Requirement</a><br /> 
Haozhe Jiang*, <b>Qiwen Cui</b>*, Zhihan Xiong, Maryam Fazel, Simon S. Du<br />
International Conference on Learning Representations (ICLR) 2023<br /> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.01880">Learning in Congestion Games with Bandit Feedback</a><br /> 
<b>Qiwen Cui</b>*, Zhihan Xiong*, Maryam Fazel, Simon S. Du<br />
Conference on Neural Information Processing Systems (NeurIPS) 2022<br /> </p>
</li>
</ul>
<h3>Reinforcement Learning for LLM</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2410.00773">BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and Multistructured Data</a><br />
Xuwu Wang, <b>Qiwen Cui</b>, Yunzhe Tao, Yiran Wang, Ziwei Chai, Xiaotian Han, Boyi Liu, Jianbo Yuan, Jing Su, Guoyin Wang, Tingkai Liu, Liyu Chen, Tianyi Liu, Tao Sun, Yufeng Zhang, Sirui Zheng, Quanzeng You, Yang Yang, Hongxia Yang<br />
ArXiv: 2410.00773<br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2403.07191">(N,K)-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model</a><br />
Yufeng Zhang, Liyu Chen, Boyi Liu, Yingxiang Yang, <b>Qiwen Cui</b>, Yunzhe Tao, Hongxia Yang<br />
ArXiv: 2403.07191<br /></p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
